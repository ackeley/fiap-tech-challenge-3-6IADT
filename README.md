# ğŸ¥ Assistente MÃ©dico Inteligente com LLM, LangChain e LangGraph

Este projeto implementa um **assistente mÃ©dico virtual em portuguÃªs (pt-BR)**, treinado com **dados internos (sintÃ©ticos)** de um hospital, capaz de **auxiliar condutas clÃ­nicas**, **responder dÃºvidas mÃ©dicas** e **orquestrar fluxos automatizados**, sempre respeitando **regras rÃ­gidas de seguranÃ§a, validaÃ§Ã£o humana e auditabilidade**.

> âš ï¸ O sistema **NÃƒO prescreve medicamentos**, **NÃƒO define doses** e **NÃƒO substitui decisÃµes mÃ©dicas**.

---

## ğŸ¯ Objetivo

Demonstrar como **modelos de linguagem (LLMs)** podem ser usados de forma **Ã©tica, segura e explicÃ¡vel** na Ã¡rea da saÃºde, integrando:

- Fine-tuning com dados internos
- RecuperaÃ§Ã£o de conhecimento (RAG)
- OrquestraÃ§Ã£o de decisÃµes clÃ­nicas
- Logging e auditoria
- ValidaÃ§Ã£o humana obrigatÃ³ria

---

## ğŸ§  Arquitetura Geral

- **LLM Base:** Qwen/Qwen2.5-3B-Instruct  
- **Fine-tuning:** LoRA (PEFT)  
- **RAG:** LangChain + FAISS  
- **OrquestraÃ§Ã£o:** LangGraph  
- **SeguranÃ§a:** Guardrails + validaÃ§Ã£o humana  
- **Logs:** JSONL para auditoria  

---

## ğŸ“‚ Estrutura do Projeto

```text
medical-assistant/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ synthetic/
â”‚   â”‚   â”œâ”€â”€ train.jsonl
â”‚   â”‚   â”œâ”€â”€ valid.jsonl
â”‚   â”‚   â””â”€â”€ protocols/
â”‚   â”‚       â””â”€â”€ protocolo_pneumonia.md
â”‚   â””â”€â”€ vectorstore/
â”‚       â””â”€â”€ protocols_faiss/
â”‚
â”œâ”€â”€ lora_adapter/
â”‚   â”œâ”€â”€ adapter_config.json
â”‚   â””â”€â”€ adapter_model.safetensors
â”‚
â”œâ”€â”€ logs/
â”‚   â””â”€â”€ assistant_audit.jsonl
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ training/
â”‚   â”‚   â””â”€â”€ build_synthetic_dataset.py
â”‚   â”‚
â”‚   â”œâ”€â”€ rag/
â”‚   â”‚   â”œâ”€â”€ ingest_protocols.py
â”‚   â”‚   â”œâ”€â”€ retriever.py
â”‚   â”‚   â””â”€â”€ test_retriever.py
â”‚   â”‚
â”‚   â”œâ”€â”€ assistant/
â”‚   â”‚   â”œâ”€â”€ llm_local.py
â”‚   â”‚   â””â”€â”€ rag_assistant.py
â”‚   â”‚
â”‚   â”œâ”€â”€ safety/
â”‚   â”‚   â”œâ”€â”€ logger.py
â”‚   â”‚   â””â”€â”€ validator.py
â”‚   â”‚
â”‚   â””â”€â”€ flows/
â”‚       â””â”€â”€ clinical_flow.py
â”‚
â””â”€â”€ README.md
```

## InstalaÃ§Ã£o e ExecuÃ§Ã£o

Siga os passos abaixo para configurar e executar o projeto localmente.

### PrÃ©-requisitos

-   Python 3.12.9 ou superior.

### Passo 1: Clonar o RepositÃ³rio

```bash
git clone https://github.com/ackeley/fiap-tech-challenge-3-6IADT
cd fiap-tech-challenge-3-6IADT
```

### Passo 2: Configurar o Ambiente Virtual

Ã‰ altamente recomendÃ¡vel usar um ambiente virtual para isolar as dependÃªncias.

```bash
# Criar o ambiente
python -m venv venv

# Ativar o ambiente
# No Windows:
# venv\Scripts\activate
# No macOS/Linux:
source venv/bin/activate
```

### Passo 3: Instalar as DependÃªncias

```bash
pip install -r requirements.txt
```

* requirements.txt â†’ dependÃªncias do projeto
* requirements.lock.txt â†’ ambiente testado 

### Passo 4: Verificar estrutura mÃ­nima esperada
VocÃª precisa ter pelo menos:
```text
data/synthetic/protocols/protocolo_pneumonia.md
data/synthetic/train.jsonl
data/synthetic/valid.jsonl
```

### Passo 5: Indexar protocolos (criar FAISS)
```bash
python -m src.rag.ingest_protocols
```

### Passo 6: Testar Retriever (deve imprimir trecho + fonte)
```bash
python -m src.rag.test_retriever
```

VocÃª deve ver algo como:

- â€œTrecho 1 | Fonte: protocolo_pneumonia.mdâ€

### Passo 7: Preparar o LoRA adapter (obrigatÃ³rio para rodar a LLM personalizada)
```text
lora_adapter/adapter_config.json
lora_adapter/adapter_model.safetensors
```
** Essa pasta vem do Colab (lora_adapter.zip) e deve ser descompactada na raiz do projeto, pois foi onde foi treinado o modelo.


### Passo 8: Rodar o Assistente RAG (LangChain + LLM + fontes)
```bash
python -m src.assistant.rag_assistant

```

Resultado esperado:

- resposta em pt-BR

- sem prescriÃ§Ã£o

- com â€œFontes: â€¦â€

### Passo 9: Rodar o fluxo LangGraph (pipeline automatizado)
```bash
python -m src.flows.clinical_flow
```

Resultado esperado:

- severidade

- exames pendentes

- alerta (true/false)

- resposta

- logs gravados

### Passo 10: Conferir auditoria (logs)
```text
logs/assistant_audit.jsonl
```

Cada execuÃ§Ã£o registra:

- pergunta

- paciente

- trechos recuperados

- fontes

- resultado do safety check


## ğŸ§ª Dataset e Fine-tuning

### ğŸ”¹ Dataset

O dataset utilizado neste projeto Ã© **100% sintÃ©tico e anonimizado**, desenvolvido exclusivamente para fins de pesquisa, experimentaÃ§Ã£o e demonstraÃ§Ã£o tÃ©cnica.

Ele Ã© baseado em:

- Protocolos clÃ­nicos internos
- Perguntas frequentes realizadas por mÃ©dicos
- Exemplos de laudos, triagens e orientaÃ§Ãµes clÃ­nicas
- SimulaÃ§Ãµes de cenÃ¡rios hospitalares reais

**Formato dos dados:**
- Arquivos `.jsonl` (JSON Lines)
- Cada linha representa uma interaÃ§Ã£o independente

**Estrutura dos registros:**
- `instruction`: instruÃ§Ã£o principal para o modelo
- `input`: contexto clÃ­nico ou dados do paciente (anonimizados)
- `output`: resposta esperada do assistente

---

### ğŸ”¹ Fine-tuning

O fine-tuning do modelo foi realizado utilizando a tÃ©cnica **LoRA (Low-Rank Adaptation)**, que permite adaptar modelos de grande porte com **baixo custo computacional** e **mÃ­nima alteraÃ§Ã£o do modelo base**.

**CaracterÃ­sticas do processo:**

- ExecuÃ§Ã£o em ambiente com GPU (ex: Google Colab)
- Uso de PEFT (Parameter-Efficient Fine-Tuning)
- PreservaÃ§Ã£o completa do modelo original
- Ajustes focados exclusivamente no domÃ­nio clÃ­nico

**Vantagens da abordagem:**

- ReduÃ§Ã£o significativa de custo
- Facilidade de versionamento
- Adequado para ambientes regulados
- Menor risco de degradaÃ§Ã£o do modelo base

**Resultado do treinamento:**

- Adaptadores treinados armazenados na pasta:
  ```text
  lora_adapter/
  ``` 

  **Arquivos principais:**

- `adapter_config.json`  
- `adapter_model.safetensors`  

Esses adaptadores sÃ£o **carregados dinamicamente durante a execuÃ§Ã£o do assistente**, permitindo alternar ou versionar ajustes do modelo sem necessidade de novo treinamento.

---

## ğŸ” RAG â€” Retrieval Augmented Generation

O assistente **nÃ£o responde apenas com conhecimento do modelo**.

**Fluxo RAG:**

- Protocolos clÃ­nicos em arquivos `.md` sÃ£o indexados  
- Embeddings gerados com `sentence-transformers`  
- Vetores armazenados em **FAISS**  

A cada pergunta:

- Trechos relevantes sÃ£o recuperados  
- O contexto Ã© injetado no prompt  
- A resposta Ã© gerada com base nas fontes  

Isso garante **respostas mais seguras, rastreÃ¡veis e facilmente atualizÃ¡veis**.

---

## ğŸ” SeguranÃ§a e ValidaÃ§Ã£o

### ğŸ›¡ï¸ Guardrails

Bloqueio automÃ¡tico de conteÃºdo sensÃ­vel, como:

- PrescriÃ§Ã£o de medicamentos  
- Dosagens e posologia  
- Receitas e orientaÃ§Ãµes terapÃªuticas diretas  

Implementado por meio de:

- ExpressÃµes regulares (Regex)  
- ValidaÃ§Ã£o pÃ³s-geraÃ§Ã£o  

---

### ğŸ‘¨â€âš•ï¸ ValidaÃ§Ã£o Humana

- **Toda resposta exige validaÃ§Ã£o de um mÃ©dico responsÃ¡vel**  
- Nenhuma decisÃ£o clÃ­nica Ã© automatizada ou tomada pela IA  

---

## ğŸ§¾ Logging e Auditoria

Cada execuÃ§Ã£o gera um registro estruturado em:

```bash
logs/assistant_audit.jsonl
```

Inclui:

- Timestamp  
- Pergunta realizada  
- Dados do paciente (anonimizados)  
- Trechos recuperados via RAG  
- Fontes utilizadas  
- Resultado do safety check  
- Tipo de evento (`ALERT` / `NO_ALERT`)  

---

## ğŸ” LangGraph â€” Fluxo ClÃ­nico Automatizado

O **LangGraph** coordena todo o fluxo clÃ­nico:

1. Recebe dados do paciente + pergunta  
2. Verifica exames pendentes  
3. Avalia a gravidade do caso  
4. Executa recuperaÃ§Ã£o via RAG  
5. Aplica validaÃ§Ãµes de seguranÃ§a  
6. Decide se gera alerta  
7. Registra auditoria  
8. Finaliza o fluxo  

---

## â–¶ï¸ Como Executar

### 1ï¸âƒ£ Indexar protocolos clÃ­nicos
```bash
python -m src.rag.ingest_protocols
```

### 2ï¸âƒ£ Testar recuperaÃ§Ã£o de contexto
```bash
python -m src.rag.test_retriever
```

### 3ï¸âƒ£ Executar assistente RAG
```bash
python -m src.assistant.rag_assistant
```
### 4ï¸âƒ£ Executar fluxo completo com LangGraph
```bash
python -m src.flows.clinical_flow